{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('./poetry/poetry.txt')\n",
    "n = 0\n",
    "poetries = []\n",
    "for line in f:\n",
    "    line = line.decode('UTF8').strip('\\n')\n",
    "    poetries.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for p in poetries:\n",
    "    all_words += [word for word in p]\n",
    "counter = collections.Counter(all_words)\n",
    "\n",
    "counter = sorted(counter.items(), key = lambda x:-x[1])\n",
    "\n",
    "idx_to_words, _ = zip(*counter)\n",
    "idx_to_words = idx_to_words[:len(idx_to_words)] + (' '.decode('UTF8'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_to_idx = dict(zip(idx_to_words, range(len(idx_to_words))))\n",
    "poetry_vector = [ list(map(lambda word: word_to_idx.get(word,len(idx_to_words)), poetry)) for poetry in poetries]\n",
    "def data_batch(start, end):\n",
    "    batches = []\n",
    "    for i in xrange(start,end):\n",
    "        batches.append(poetry_vector[i])\n",
    "    \n",
    "    length = max(map(len, batches))\n",
    "    \n",
    "    xdata = np.full([end - start, length], word_to_idx[' '], np.int32)\n",
    "    for i in range(end - start):\n",
    "        xdata[i, :len(batches[i])] = batches[i]\n",
    "    \n",
    "    ydata = np.copy(xdata)\n",
    "    ydata[:,:-1] = xdata[:,1:]\n",
    "    print '-----------',xdata.shape,ydata.shape\n",
    "    return xdata, ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 8\n",
    "vocab_size = len(idx_to_words)\n",
    "hidden_size = 16\n",
    "#num_steps = 10\n",
    "#lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size)\n",
    "#cell = tf.contrib.rnn.MultiRNNCell([lstm_cell] * 2)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(hidden_size) for _ in range(2)])\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [None, None])#第一个维度是batch_size,第二个维度是num_steps\n",
    "targets = tf.placeholder(tf.int32, [None, None])#跟上面一致\n",
    "\n",
    "embedding = tf.get_variable(name='embedding', shape=[len(idx_to_words), hidden_size])\n",
    "\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "state = initial_state\n",
    "\n",
    "#with tf.variable_scope('RNN'):\n",
    "#    for time_step in range(dataset.sample_len):\n",
    "#        if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
    "#        cell_output, state = cell(inputs[:,time_step,:], state)\n",
    "#        outputs.append(cell_output)\n",
    "        \n",
    "        \n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state)\n",
    "#output = tf.reshape(tf.concat(outputs, 1), [-1, hidden_size])\n",
    "output = tf.reshape(outputs, [-1, hidden_size])\n",
    "\n",
    "\n",
    "weight = tf.get_variable('weight', [hidden_size, vocab_size])\n",
    "bias = tf.get_variable('bias', [vocab_size])\n",
    "logits = tf.matmul(output, weight) + bias\n",
    "\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(targets,[-1])],\n",
    "                                                          [tf.ones_like(tf.reshape(targets,[-1]), dtype = tf.float32)])\n",
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "\n",
    "#final_state = state\n",
    "\n",
    "trainable_variables = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, trainable_variables), clip_norm=5)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0)\n",
    "train_op = optimizer.apply_gradients(zip(grads, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 534) (8, 534)\n",
      "(4272, 7648)\n",
      "(8, 534)\n",
      "----------- (8, 246) (8, 246)\n",
      "(1968, 7648)\n",
      "(8, 246)\n",
      "----------- (8, 246) (8, 246)\n",
      "(1968, 7648)\n",
      "(8, 246)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    epoch = 10\n",
    "    for i in xrange(epoch):\n",
    "        x, y = data_batch(i,i+batch_size)\n",
    "        sess.run(train_op, feed_dict={input_data:x, targets: y})\n",
    "    \n",
    "    #saver.save(sess,'./model/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7648)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
